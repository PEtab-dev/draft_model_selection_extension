{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1bc86d",
   "metadata": {},
   "source": [
    "# Example usage with Python 3\n",
    "This notebook demonstrates usage of `petab_select` to perform forward selection in a Python 3 script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e42ea66",
   "metadata": {},
   "source": [
    "## Problem setup with initial model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427cbd52",
   "metadata": {},
   "source": [
    "Dependencies are imported. A model selection problem is loaded from the specification files. Some helper methods are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab391ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information about the model selection problem.\n",
      "\n",
      "YAML path: model_selection/petab_select_problem.yaml\n",
      "Method: forward\n",
      "Criterion: AIC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import petab_select\n",
    "from petab_select import ForwardCandidateSpace, Model\n",
    "\n",
    "# Load the PEtab Select problem.\n",
    "select_problem = petab_select.Problem.from_yaml(\n",
    "    'model_selection/petab_select_problem.yaml'\n",
    ")\n",
    "# Fake criterion values as a surrogate for a model calibration tool.\n",
    "fake_criterion = {\n",
    "    'M1_0': 200,\n",
    "    'M1_1': 150,\n",
    "    'M1_2': 140,\n",
    "    'M1_3': 130,\n",
    "    'M1_4': -40,\n",
    "    'M1_5': -70,\n",
    "    'M1_6': -110,\n",
    "    'M1_7': 50,\n",
    "}\n",
    "\n",
    "\n",
    "def print_model(model: Model) -> None:\n",
    "    \"\"\"Helper method to view model attributes.\"\"\"\n",
    "    print(\n",
    "        f\"\"\"\\\n",
    "Model subspace ID: {model.model_subspace_id}\n",
    "PEtab YAML location: {model.petab_yaml}\n",
    "Custom model parameters: {model.parameters}\n",
    "Model hash: {model.get_hash()}\n",
    "Model ID: {model.model_id}\n",
    "{select_problem.criterion}: {model.get_criterion(select_problem.criterion, compute=False)}\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "def calibrate(model: Model, fake_criterion=fake_criterion) -> None:\n",
    "    \"\"\"Set model criterion values to fake values that could be the output of a calibration tool.\n",
    "\n",
    "    Each model subspace in this problem contains only one model, so a model-specific criterion can\n",
    "    be indexed by the model subspace ID.\n",
    "    \"\"\"\n",
    "    model.set_criterion(\n",
    "        select_problem.criterion, fake_criterion[model.model_subspace_id]\n",
    "    )\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"\"\"Information about the model selection problem.\n",
    "\n",
    "YAML path: {select_problem.yaml_path}\n",
    "Method: {select_problem.method}\n",
    "Criterion: {select_problem.criterion}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88172819",
   "metadata": {},
   "source": [
    "## First iteration\n",
    "\n",
    "Neighbors of the initial model in the model space are identified for testing. Here, no initial model is specified. If an initial model is required for the algorithm, PEtab Select can automatically use a virtual initial model, if such a model is defined. For example, for the forward and backward methods, the virtual initial model defaults to a model with no parameters estimated, and all parameters estimated, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080d08d4",
   "metadata": {},
   "source": [
    "The model candidate space is setup with the initial model. The model space is then used to find neighbors to the initial model. The candidate space is used to calculate distances between models, and whether a candidate model represents a valid move in model space.\n",
    "\n",
    "The in-built `ForwardCandidateSpace` uses the following properties to identify candidate models:\n",
    "- previously estimated parameters must not be fixed;\n",
    "- the number of estimated parameters must increase; and\n",
    "- the increase in the number of estimated parameters must be minimal.\n",
    "\n",
    "The model space keeps a history of identified neighbors, such that subsequent calls ignore previously identified neighbors. This can be disabled by changing usage to `petab_select.ModelSpace.search(..., exclude=False)`, or reset to forget all history with `petab_select.ModelSpace.reset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f327ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_space = petab_select.ui.candidates(problem=select_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9245832",
   "metadata": {},
   "source": [
    "Model IDs default to the model hash, which is generated from hashing the model subspace ID and model parameterization.\n",
    "\n",
    "Here, the model identified is a model with all possible parameters fixed. This is because the default virtual initial model is the same parameterization, and the closest model in the \"real\" model subspace is the same parameterization. If the initial model was from the \"real\" model subspace, then candidate models would be true forward steps in the subspace (e.g. an increase in the number of estimated parameters)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996aed0",
   "metadata": {},
   "source": [
    "Each of the candidate models includes information that should be sufficient for model calibration with any suitable tool that supports PEtab.\n",
    "\n",
    "NB: the `petab_yaml` is for the original PEtab problem, and would need to be customized by `parameters` to be the actual candidate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edefa697",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dae6c507cf58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcandidate_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'models'"
     ]
    }
   ],
   "source": [
    "for candidate_model in candidate_space.models:\n",
    "    print_model(candidate_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7104888",
   "metadata": {},
   "source": [
    "At this point, a model calibration tool is used to find the best of the test models, according to some criterion. PEtab select can select the best model from a collection of models that provide a value for this criterion, or a specific model can be supplied. Here, PEtab Select will be used to select the best model from multiple models. At the end of the following iterations, a specific model will be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f027ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fake criterion values that might be the output of a model calibration tool.\n",
    "for candidate_model in candidate_space.models:\n",
    "    calibrate(candidate_model)\n",
    "select_problem.add_calibrated_models(candidate_space.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c51dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_best_model = select_problem.get_best(candidate_space.models)\n",
    "print_model(local_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031b2eaf",
   "metadata": {},
   "source": [
    "## Second iteration\n",
    "The process then repeats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b167b4",
   "metadata": {},
   "source": [
    "The chosen model is used as the predecessor model, such that neighboring models are identified with respect to the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15c30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "petab_select.ui.candidates(\n",
    "    problem=select_problem,\n",
    "    candidate_space=candidate_space,\n",
    "    predecessor_model=select_problem.get_best(candidate_space.models),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6969ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_model in candidate_space.models:\n",
    "    print_model(candidate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c54e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fake criterion values that might be the output of a model calibration tool.\n",
    "for candidate_model in candidate_space.models:\n",
    "    calibrate(candidate_model)\n",
    "select_problem.add_calibrated_models(candidate_space.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69185082",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_best_model = select_problem.get_best(candidate_space.models)\n",
    "print_model(local_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3e8077",
   "metadata": {},
   "source": [
    "## Third iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3468d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "petab_select.ui.candidates(\n",
    "    problem=select_problem,\n",
    "    candidate_space=candidate_space,\n",
    "    predecessor_model=select_problem.get_best(candidate_space.models),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_model in candidate_space.models:\n",
    "    print_model(candidate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26614e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fake criterion values that might be the output of a model calibration tool.\n",
    "for candidate_model in candidate_space.models:\n",
    "    calibrate(candidate_model)\n",
    "select_problem.add_calibrated_models(candidate_space.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db19881",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_best_model = select_problem.get_best(candidate_space.models)\n",
    "print_model(local_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dca7bff",
   "metadata": {},
   "source": [
    "## Fourth iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "petab_select.ui.candidates(\n",
    "    problem=select_problem,\n",
    "    candidate_space=candidate_space,\n",
    "    predecessor_model=select_problem.get_best(candidate_space.models),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfff3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_model in candidate_space.models:\n",
    "    print_model(candidate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fake criterion values that might be the output of a model calibration tool.\n",
    "for candidate_model in candidate_space.models:\n",
    "    calibrate(candidate_model)\n",
    "select_problem.add_calibrated_models(candidate_space.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a36e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_best_model = select_problem.get_best(candidate_space.models)\n",
    "print_model(local_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44320e4e",
   "metadata": {},
   "source": [
    "## Sixth iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30344b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "petab_select.ui.candidates(\n",
    "    problem=select_problem,\n",
    "    candidate_space=candidate_space,\n",
    "    predecessor_model=select_problem.get_best(candidate_space.models),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23317d8d",
   "metadata": {},
   "source": [
    "The `M1_7` model is the most complex model in the model space (all parameters in the space are estimated), so no valid neighbors are identified for the forward selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843fcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of candidate models: {len(candidate_space.models)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d1090e",
   "metadata": {},
   "source": [
    "At this point, the results of the model calibration tool for the different models can be used to select the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219d27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = select_problem.get_best(select_problem.calibrated_models)\n",
    "print_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d1f895",
   "metadata": {},
   "source": [
    "## Seventh iteration\n",
    "Note that there can exist additional, uncalibrated models in the model space, after a single forward algorithm terminates. These additional models can be identified with the brute-force method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacda13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_space = petab_select.BruteForceCandidateSpace()\n",
    "petab_select.ui.candidates(\n",
    "    problem=select_problem,\n",
    "    candidate_space=candidate_space,\n",
    "    excluded_models=select_problem.calibrated_models,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7440cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate_model in candidate_space.models:\n",
    "    print_model(candidate_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
